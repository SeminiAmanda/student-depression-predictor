{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3f5fee",
   "metadata": {},
   "source": [
    "Model Development (Logistic Regression Only)\n",
    "\n",
    "This notebook implements model development using the final features from 'final_features_student_depression.csv', focusing solely on Logistic Regression.\n",
    "\n",
    "Steps:\n",
    "- Split data into train/validation/test sets (70/15/15).\n",
    "- Evaluate Logistic Regression as the baseline model.\n",
    "- Use K-fold cross-validation for robust performance estimates.\n",
    "- Perform hyperparameter tuning using GridSearchCV.\n",
    "\n",
    "The goal is to optimize and evaluate a Logistic Regression model for predicting 'Depression' and save it for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9bbf223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "335afc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (19529, 10), Val shape: (4186, 10), Test shape: (4186, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load the final features dataset and split into train/validation/test\n",
    "\n",
    "# Load the preprocessed dataset from Feature_Engineering.ipynb\n",
    "csv_path = 'final_features_student_depression.csv'\n",
    "df_final = pd.read_csv(csv_path)\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df_final.drop(columns=['Depression', 'id'])  # Drop target and irrelevant 'id'\n",
    "y = df_final['Depression']\n",
    "\n",
    "# Split into train (70%), validation (15%), test (15%)\n",
    "# First, split into train+val (85%) and test (15%)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "# Then, split train+val into train (70%) and validation (15%)\n",
    "# 0.1765 ≈ 15/85 to get 15% of original data as validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1765, random_state=42)\n",
    "\n",
    "# Verify shapes\n",
    "print(f'Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}')\n",
    "# Expected: Train ~19,530 rows, Val ~4,185 rows, Test ~4,185 rows (10 features each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092ef81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV F1-macro: 0.8393 ± 0.0040\n"
     ]
    }
   ],
   "source": [
    "# Baseline Logistic Regression with Cross-Validation\n",
    "# Evaluate Logistic Regression using 5-fold CV to get robust performance estimates\n",
    "\n",
    "# Define K-Fold CV (5 folds, shuffled)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Function to evaluate model with CV and return F1-macro score\n",
    "def evaluate_model(model, X, y, model_name):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "    print(f'{model_name} CV F1-macro: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}')\n",
    "    return cv_scores.mean(), cv_scores.std()\n",
    "\n",
    "# Baseline: Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_mean, logreg_std = evaluate_model(logreg, X_train, y_train, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb6ad187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Params: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Logistic Regression CV F1: 0.8394\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1708\n",
      "           1       0.86      0.90      0.88      2478\n",
      "\n",
      "    accuracy                           0.85      4186\n",
      "   macro avg       0.85      0.84      0.85      4186\n",
      "weighted avg       0.85      0.85      0.85      4186\n",
      "\n",
      "Validation ROC-AUC: 0.9250425997017313\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning for Logistic Regression\n",
    "# Tune Logistic Regression using GridSearchCV\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "logreg_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],   # Inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'],        # Regularization type\n",
    "    'solver': ['liblinear']         # Solver compatible with both 'l1' and 'l2' (binary classification)\n",
    "}\n",
    "\n",
    "\n",
    "# Perform GridSearchCV\n",
    "logreg_grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=1000, random_state=42),\n",
    "    param_grid=logreg_param_grid,\n",
    "    cv=kf,                          # StratifiedKFold or KFold defined earlier\n",
    "    scoring='f1_macro',             # Macro F1 is good for imbalanced classes\n",
    "    n_jobs=-1                       # Use all cores\n",
    ")\n",
    "logreg_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(f'Best Logistic Regression Params: {logreg_grid.best_params_}')\n",
    "print(f'Best Logistic Regression CV F1: {logreg_grid.best_score_:.4f}')\n",
    "\n",
    "# Select best model\n",
    "best_model = logreg_grid.best_estimator_\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "print('Validation Classification Report:\\n', classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Optional: ROC-AUC for binary classification\n",
    "if len(np.unique(y_val)) == 2:\n",
    "    y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "    print(\"Validation ROC-AUC:\", roc_auc_score(y_val, y_val_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32099adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1749\n",
      "           1       0.85      0.87      0.86      2437\n",
      "\n",
      "    accuracy                           0.84      4186\n",
      "   macro avg       0.83      0.83      0.83      4186\n",
      "weighted avg       0.84      0.84      0.84      4186\n",
      "\n",
      "Test Confusion Matrix:\n",
      " [[1374  375]\n",
      " [ 307 2130]]\n",
      "Test Accuracy: 0.8370759675107501\n",
      "Best model saved as best_logreg_depression_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Final Evaluation on Test Set\n",
    "# Use the best Logistic Regression model on the held-out test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print('Test Classification Report:\\n', classification_report(y_test, y_test_pred))\n",
    "print('Test Confusion Matrix:\\n', confusion_matrix(y_test, y_test_pred))\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Save the best model for deployment\n",
    "joblib.dump(best_model, 'best_logreg_depression_model.pkl')\n",
    "print('Best model saved as best_logreg_depression_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a6cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
