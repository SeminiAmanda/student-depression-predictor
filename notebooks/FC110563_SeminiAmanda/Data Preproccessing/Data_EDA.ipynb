{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "478dcbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "import scipy.stats as stats\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, accuracy_score\n",
    "import warnings  \n",
    "import math\n",
    "\n",
    "# Ignore all warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e804476",
   "metadata": {},
   "source": [
    "üìå\n",
    "Before diving into analysis, it‚Äôs essential to understand the structure, shape, and quality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc991f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "#df = pd.read_csv('../../../raw/student_depression_dataset.csv')\n",
    "import os\n",
    "\n",
    "# Get the project root based on the notebook's location\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../../'))   # go up to project root\n",
    "\n",
    "# Create a path to your dataset\n",
    "csv_path = os.path.join(project_root, 'Data', 'raw', 'student_depression_dataset.csv')\n",
    "\n",
    "# Load it\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df_copy = df.copy()\n",
    "except FileNotFoundError:\n",
    "    print(\"CSV not found! Check path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head()# print first 5 rows of the dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ce444a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27901, 18)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4624acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539414c",
   "metadata": {},
   "source": [
    "üí¨ Interpretation:\n",
    "\n",
    "The dataset consists of various features such as Age, Gender, Academic Pressure, Study Satisfaction, Financial Stress, etc.\n",
    "\n",
    "The goal is to prepare and clean these fields for meaningful analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa7ce823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns to category\n",
    "for col in df_copy.select_dtypes(include='object').columns:\n",
    "    if col != 'Financial Stress':  # Exclude Financial Stress from category conversion\n",
    "        df_copy[col] = df_copy[col].astype('category')\n",
    "\n",
    "# Convert Financial Stress to float\n",
    "df_copy['Financial Stress'] = pd.to_numeric(df_copy['Financial Stress'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb19bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_copy == 0).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2cd00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_copy.columns:\n",
    "    print(f\"{col}: {df_copy[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d1681e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Sleep Duration'] = df_copy['Sleep Duration'].replace('Others', np.nan)\n",
    "df_copy['Financial Stress'] = df_copy['Financial Stress'].replace('?', np.nan)\n",
    "df_copy['Dietary Habits'] = df_copy['Dietary Habits'].replace('Others', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbfb1464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Financial Stress column to numeric and replacing null values with the median\n",
    "df_copy['Financial Stress'] = pd.to_numeric(df_copy['Financial Stress'], errors='coerce')\n",
    "df_copy['Financial Stress'] = df_copy['Financial Stress'].fillna(df_copy['Financial Stress'].median())\n",
    "\n",
    "\n",
    "# Creating lists with categorical variables and numeric variables according to their DTYPE\n",
    "categorical_col = df_copy.select_dtypes(include=['object']).columns.to_list()\n",
    "numerical_col = df_copy.select_dtypes(include=['int64','float64']).columns.to_list()\n",
    "\n",
    "# Excluding the 'Id' column\n",
    "numerical_col = [col for col in numerical_col if col not in ['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "708f552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the \"Yes/No\" values in \"1/0\" values\n",
    "binary_map = {'Yes' : 1,'No' : 0}\n",
    "df_copy['Have you ever had suicidal thoughts ?'] = df_copy['Have you ever had suicidal thoughts ?'].map(binary_map)\n",
    "df_copy['Family History of Mental Illness']= df_copy['Family History of Mental Illness'].map(binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3567c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see statistics for all columns, including object (categorical) columns, use:\n",
    "df_copy.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f99192",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def value_counts_pretty(series, column_name=\"Value\"):\n",
    "    value_counts = series.value_counts(dropna=False)\n",
    "    percentages = series.value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [column_name, \"Count\", \"Percentage\"]\n",
    "    table.align[column_name] = \"c\"\n",
    "    table.align[\"Count\"] = \"r\"\n",
    "    table.align[\"Percentage\"] = \"r\"\n",
    "\n",
    "    for value, count in value_counts.items():\n",
    "        display_value = \"NaN/Missing\" if pd.isna(value) else str(value)\n",
    "        pct = percentages[value]\n",
    "        table.add_row([display_value, count, f\"{pct:.2f}%\"])\n",
    "    return table\n",
    "\n",
    "colsJob = ['Work Pressure', 'Job Satisfaction','Gender' ,'Age' ,'City' ,'Profession' ,'Academic Pressure' ,'Work Pressure' ,\n",
    "           'CGPA' ,'Job Satisfaction' ,'Sleep Duration' ,'Degree','Dietary Habits' ,'Study Satisfaction' ,'Have you ever had suicidal thoughts ?', \n",
    "           'Work/Study Hours','Financial Stress','Family History of Mental Illness','Depression'   ]                            \n",
    "\n",
    "for col in colsJob:\n",
    "    print(f\"\\n Value counts for '{col}':\")\n",
    "    print(value_counts_pretty(df_copy[col], col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41132a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts_pretty(series, column_name=\"Value\", threshold_percentage=90):\n",
    "    value_counts = series.value_counts(dropna=False)\n",
    "    percentages = series.value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "    # Check if any percentage meets the threshold\n",
    "    if not (percentages >= threshold_percentage).any():\n",
    "        return None # Return None if no value meets the threshold\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [column_name, \"Count\", \"Percentage\"]\n",
    "    table.align[column_name] = \"c\"\n",
    "    table.align[\"Count\"] = \"r\"\n",
    "    table.align[\"Percentage\"] = \"r\"\n",
    "\n",
    "    for value, count in value_counts.items():\n",
    "        display_value = \"NaN/Missing\" if pd.isna(value) else str(value)\n",
    "        pct = percentages[value]\n",
    "        table.add_row([display_value, count, f\"{pct:.2f}%\"])\n",
    "    return table\n",
    "\n",
    "colsJob = ['Work Pressure', 'Job Satisfaction','Gender' ,'Age' ,'City' ,'Profession' ,'Academic Pressure' ,\n",
    "           'CGPA' ,'Sleep Duration' ,'Dietary Habits' ,'Study Satisfaction' ,'Have you ever had suicidal thoughts ?',\n",
    "           'Work/Study Hours','Financial Stress','Family History of Mental Illness','Depression']\n",
    "\n",
    "for col in colsJob:\n",
    "    table_output = value_counts_pretty(df_copy[col], col)\n",
    "    if table_output: # Only print if the table is not None (i.e., meets the threshold)\n",
    "        print(f\"\\n Value counts for '{col}':\")\n",
    "        print(table_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c61e16d",
   "metadata": {},
   "source": [
    "üîç Key Insights \n",
    "1. Work Pressure\n",
    "Observation: 99.99% report 0.0; very low variance.\n",
    "\n",
    "2. Job Satisfaction\n",
    "Observation: 99.97% report 0.0; very skewed.\n",
    "\n",
    "3. Gender\n",
    "Observation: 'Male' is the dominant category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop NaNs from numerical columns\n",
    "plot_data = df_copy[numerical_col].dropna()\n",
    "\n",
    "# Set layout: 2 plots per row\n",
    "ncols = 2\n",
    "nrows = math.ceil(len(numerical_col) / ncols)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 5 * nrows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = ['skyblue', 'salmon']\n",
    "\n",
    "# Plot each feature\n",
    "for i, feature in enumerate(numerical_col):\n",
    "    color = colors[i % len(colors)]\n",
    "    sns.histplot(data=plot_data, x=feature, bins=25, kde=True, ax=axes[i], color=color)\n",
    "    axes[i].set_title(f'Distribution of {feature}', fontsize=14)\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].grid(True)\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Title and layout\n",
    "plt.suptitle(\"Distribution of Numerical Features\", fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb856f49",
   "metadata": {},
   "source": [
    "1. Work Pressure\n",
    "Insight: Extremely right-skewed; almost all values are 0.0, with very few > 0.\n",
    "Not likely useful in numeric form.\n",
    "\n",
    "2. Job Satisfaction\n",
    "Insight: Almost everyone reports 0.0, indicating extreme class imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11179bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = df_copy.select_dtypes(include='category').columns.tolist()\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = math.ceil(len(categorical_col) / n_cols)\n",
    "\n",
    "plt.figure(figsize=(14, 5 * n_rows))\n",
    "\n",
    "for i, col in enumerate(categorical_col, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.countplot(data=df, x=col, color='skyblue')\n",
    "    plt.title(f'{col} Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc4396e",
   "metadata": {},
   "source": [
    "1. Profession\n",
    "Strong class imbalance ‚Üí reduce to ‚ÄúStudent‚Äù vs ‚ÄúOther‚Äù.\n",
    "Or group rare professions into \"Other\" category.\n",
    "\n",
    "2. Dietary Habits\n",
    "Insight: Majority are moderate or unhealthy.\n",
    "Might correlate with depression or stress levels.\n",
    "\n",
    "3. Degree\n",
    "Insight: Very high cardinality; lots of unique degree types with small counts.Reduce to broader categories (e.g., ‚ÄúUndergraduate‚Äù, ‚ÄúPostgraduate‚Äù).\n",
    "\n",
    "\n",
    "4. Suicidal Thoughts\n",
    "Insight: About 65% said 'Yes' to having had suicidal thoughts.\n",
    "Strong mental health indicator ‚Üí important feature.\n",
    "\n",
    "5. Family History of Mental Illness\n",
    "Insight: Roughly balanced between Yes (1) and No (0).\n",
    "Useful feature; keep as binary (0/1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ec8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts for all cities\n",
    "city_counts = df_copy['City'].value_counts()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(18, 8))  # Adjust width to fit all city labels\n",
    "sns.barplot(x=city_counts.index, y=city_counts.values, palette='viridis')\n",
    "\n",
    "plt.title(\"City-wise Distribution (All Cities)\", fontsize=16)\n",
    "plt.xlabel(\"City\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xticks(rotation=90)  # Rotate for readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4998e",
   "metadata": {},
   "source": [
    "City Distribution Insights\n",
    "\n",
    "High Cardinality: The dataset contains many unique city names, which can cause sparse data issues and potential overfitting in models if used directly.\n",
    "\n",
    "Top Cities: Indore, Surat, Hyderabad, and Pune have the highest respondent counts, each exceeding 1000 entries.\n",
    "\n",
    "Data Quality Issues: Several city entries appear to be errors or mislabels (e.g., 'Less Delhi', '3.0', 'City', 'M.Com'), indicating data cleaning is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for feature in numerical_col:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x='Depression', y=feature, data=df)\n",
    "    plt.title(f'{feature} vs Depression')\n",
    "    plt.xlabel('Depression Level')\n",
    "    plt.ylabel(feature)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3162733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "depression_levels = df_copy['Depression'].unique()\n",
    "\n",
    "for feature in numerical_col:\n",
    "    g = sns.displot(data=df_copy, x=feature, col='Depression', col_wrap=4, bins=10, kde=False, height=4, aspect=1.2)\n",
    "    g.fig.suptitle(f'{feature} Histogram by Depression Level', y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for feature in categorical_col:\n",
    "    try:\n",
    "        g = sns.catplot(data=df_copy, x=feature, kind='count', hue='Depression',\n",
    "                        height=4, aspect=1.5, palette='Set2')\n",
    "        g.fig.suptitle(f'{feature} Distribution by Depression Level', y=1.03)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not plot {feature}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c87614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crosstab_pretty(df_copy, row_col, col_col, normalize='all'):\n",
    "    \"\"\"\n",
    "    Display crosstab of two categorical columns with counts and percentages.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): The dataset.\n",
    "        row_col (str): First categorical column (e.g., Profession).\n",
    "        col_col (str): Second categorical column (e.g., Degree).\n",
    "        normalize (str): 'all' (default) for % of total, 'index' for row-wise %, 'columns' for col-wise %.\n",
    "    \"\"\"\n",
    "    count_table = pd.crosstab(df_copy[row_col], df_copy[col_col])\n",
    "    \n",
    "    if normalize == 'index':\n",
    "        pct_table = pd.crosstab(df_copy[row_col], df_copy[col_col], normalize='index') * 100\n",
    "    elif normalize == 'columns':\n",
    "        pct_table = pd.crosstab(df_copy[row_col], df_copy[col_col], normalize='columns') * 100\n",
    "    else:\n",
    "        pct_table = pd.crosstab(df_copy[row_col], df_copy[col_col], normalize='all') * 100\n",
    "\n",
    "    # Create PrettyTable\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [row_col, col_col, \"Count\", \"Percentage\"]\n",
    "    table.align[row_col] = \"l\"\n",
    "    table.align[col_col] = \"l\"\n",
    "    table.align[\"Count\"] = \"r\"\n",
    "    table.align[\"Percentage\"] = \"r\"\n",
    "\n",
    "    for r in count_table.index:\n",
    "        for c in count_table.columns:\n",
    "            count = count_table.loc[r, c]\n",
    "            pct = pct_table.loc[r, c]\n",
    "            table.add_row([r, c, count, f\"{pct:.2f}%\"])\n",
    "\n",
    "    return table\n",
    "\n",
    "print(crosstab_pretty(df, 'Profession', 'Degree', normalize='index'))  # Row-wise %\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b052f",
   "metadata": {},
   "source": [
    "### Degree Distribution Insights\n",
    "\n",
    "- The distribution of degree types is **highly skewed**:\n",
    "  - The top 5 degrees (`Class 12`, `B.Ed`, `B.Com`, `B.Arch`, `BCA`) represent approximately **44%** of the dataset.\n",
    "  - The bottom 10 degrees account for **less than 15%**, with several appearing in **less than 1%** of records.\n",
    "\n",
    "- This reflects a **long-tail distribution**, where many degrees are rare and sparsely represented.\n",
    "\n",
    "- Including all degree categories as features (e.g., via one-hot encoding) would introduce **high dimensionality and sparsity**, which can degrade performance for models like linear regression or logistic regression.\n",
    "\n",
    "- **Recommendation**: Group rare degrees into an `\"Other Degree\"` category to simplify modeling and reduce noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b83843",
   "metadata": {},
   "source": [
    "### Feature Elimination Consideration\n",
    "\n",
    "Based on the current data:\n",
    "\n",
    "- **City**: Contains many invalid or inconsistent entries, making it an unreliable feature. It is likely a candidate for removal.\n",
    "- **Profession**: Over 99% of respondents are labeled as \"Student\", offering little to no variance. This feature may not contribute meaningfully to model training.\n",
    "- **Work_Pressure**: The majority of entries indicate \"No work pressure\" (~99%), leading to severe class imbalance. It may be reasonable to drop this feature.\n",
    "- **Job_Satisfaction**: Similarly, around 99% of entries show \"No satisfaction\", indicating minimal variation and potential redundancy.\n",
    "\n",
    "These features can be considered for exclusion during feature selection or model optimization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
